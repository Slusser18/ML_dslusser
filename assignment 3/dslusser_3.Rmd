---
title: "dslusser_3"
author: "David Slusser"
date: "10/18/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is homework assignment number 3, using naive bayes to predict if a flight will be on time or not

```{r flight}
library(readr) # Need to load data
library(dplyr) # Selecting variables
library(caret) # For splitting into training and validation
library(ISLR)
library(e1071) # For the Naive Bayes model
library(gmodels) # For counts table
library(pROC) # For the ROC plot

flights <- read_csv("~/Desktop/School/Graduate/Machine Learning/HW/Data/FlightDelays.csv")

# We need to make variables factors
flights$DAY_WEEK <- cut(flights$DAY_WEEK,c(-Inf, 1, 2, 3, 4, 5, 6, Inf), # Convert day number to days
                        labels=c("Monday", "Tuesday", "Wednesday" ,"Thursday", "Friday", "Saturday", "Sunday"))

flightsModel <- flights %>%
  select(CRS_DEP_TIME, CARRIER, DEST, ORIGIN, DAY_WEEK, `Flight Status`) %>%
  rename(Status = `Flight Status`)

# Convert departure time into numeruc
flightsModel$CRS_DEP_TIME <- as.factor(flightsModel$CRS_DEP_TIME)

# We want the count and preportions for each airport for delayed
flightsModel %>%
  select(Status, ORIGIN) %>% # Select the variables needed
  group_by(ORIGIN, Status) %>% # Group by origin and then status to get the amount delayed/on time for airport
  summarise(Count = n()) %>% # Count the number of flights delayed/ontime at each airport
  mutate(Freq = Count / sum(Count)) # Get the frequency of flights delayed/ontime at each airport

```

At BWI (Baltimore-Washington), there were 145 flights with 37 (25.5%) delayed and 108 (74.5%) on time
At DCA (Reagan National), there were 1370 flights with 221 (16.1%) delayed and 1149 (83.9%) on time
At IAD (Dulles), there were 686 fligths with 170 (24.8%) delayed and 516 (75.2%) on time

Overall, there were 2,201 flights with 428 (19.4)% delayed and 1773 (80.6%) on time

```{r flight nb}
# We need to create and build the naive bayes model
# Start with training and validation


# Set seed and divide the data into training (60%) and validation (40%)
set.seed(1234)
Index_Train <- createDataPartition(flightsModel$Status, p= 0.6, list = FALSE)
Train <- flightsModel[Index_Train,]
Validation  <- flightsModel[-Index_Train,]

# Build a naive bayes classifier
nb_model <-naiveBayes(as.factor(Status) ~ as.factor(CRS_DEP_TIME) + CARRIER + DEST + ORIGIN + DAY_WEEK,
                      data = Train) # This is the classifier with our categorical variables
nb_model # Produces the A-prori probabilities (Probabilities from deductive reasoning)

# Predict the status of the flight using the model and the validation data set
predicted_status <-predict(nb_model, Validation) # this provides the predicted label (delayed/on time) where
                                           # P > 0.5 is the cutoff

# Show the confusion matrix of the flight status 
CrossTable(x = Validation$Status, y = predicted_status, prop.chisq = FALSE) 

# For the PROC we want the probabilities of each, so the predicted status we need the raw probabilities
predicted_status_prob <-predict(nb_model, Validation, type = "raw") # type = "raw" provides prob of each
head(predicted_status_prob) # gives first couple rows of the predicted prob. delayed is column 1 and 
                            # on time is column 2

# Get the ROC curve
# This uses the pROC package
roc(Validation$Status, predicted_status_prob[,2]) # Prob that the flight is ontime
plot.roc(Validation$Status, predicted_status_prob[,2]) # Plot of curve that the flight is ontime

```

This cross table shows us that we have 184 misclassifications

We find the Area under the curve (AUC) is 62.6%

Better curves are closer to the top left corner, but as our ROC is closer to the dashed line, our model is not as strong (also seen with the lower AUC)
